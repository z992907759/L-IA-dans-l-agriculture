import os
import json
import re
import fitz  # PyMuPDF è§£æ PDF
import torch
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_community.vectorstores import FAISS
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_core.documents import Document


# âœ… FAISS å­˜å‚¨è·¯å¾„
FAISS_INDEX_PATH = os.path.join(".", "database", "faiss_db")
DATA_FOLDER = os.path.join(".", "database", "knowledge_base")


def clean_text(text):
    """âœ… æ¸…ç†æ–‡æœ¬"""
    text = re.sub(r"\s{2,}", " ", text)  # å¤šä½™ç©ºæ ¼
    text = re.sub(r"\n{2,}", "\n", text)  # å¤šä½™æ¢è¡Œ
    return text.strip()


def process_pdf(file_path):
    """âœ… è§£æ PDF å¹¶è½¬æ¢ä¸ºé—®ç­”æ ¼å¼"""
    print(f"ğŸ“„ æ­£åœ¨å¤„ç† PDF: {file_path}")
    doc = fitz.open(file_path)
    documents = []

    for page in doc:
        text = clean_text(page.get_text("text").strip())
        if len(text) > 100:  # è¿‡æ»¤è¿‡çŸ­æ–‡æœ¬
            question = f"What information does this text provide? {text[:100]}..."
            documents.append(Document(page_content=f"Question: {question}\nAnswer: {text}"))

    return documents


def process_txt(file_path):
    """âœ… è§£æ TXT æ–‡ä»¶å¹¶è½¬æ¢ä¸ºé—®ç­”æ ¼å¼ï¼Œç¡®ä¿ FAISS å­˜å‚¨çš„æ˜¯é—®ç­”å¯¹"""
    print(f"ğŸ“„ æ­£åœ¨å¤„ç† TXT: {file_path}")
    with open(file_path, "r", encoding="utf-8", errors="ignore") as f:
        text = clean_text(f.read())

    lines = text.split("\n")
    documents = []

    for i in range(0, len(lines) - 1, 2):  # æ¯ä¸¤è¡Œä½œä¸º Q-A å¯¹
        question = lines[i].strip()
        answer = lines[i + 1].strip() if i + 1 < len(lines) else ""

        if question and answer and len(answer) > 30:  # è¿‡æ»¤æ‰æ— æ„ä¹‰çš„çŸ­å›ç­”
            documents.append(Document(page_content=f"Question: {question}\nAnswer: {answer}"))

    return documents


def process_json(file_path):
    """âœ… è§£æ JSON æ–‡ä»¶ï¼Œå¹¶ç¡®ä¿ `Question-Answer` å¯¹çš„å®Œæ•´æ€§"""
    print(f"ğŸ“„ æ­£åœ¨å¤„ç† JSON: {file_path}")
    with open(file_path, "r", encoding="utf-8") as f:
        data = json.load(f)

    documents = []
    for entry in data:
        question = entry.get("input") or entry.get("question") or entry.get("QUESTION.question", "").strip()
        answer = entry.get("response") or entry.get("answers") or entry.get("ANSWER", "").strip()

        if question and answer and len(answer) > 30:  # ç¡®ä¿å›ç­”è¶³å¤Ÿæœ‰ä¿¡æ¯é‡
            documents.append(Document(page_content=f"Question: {question}\nAnswer: {answer}"))

    return documents


def create_faiss_index():
    """âœ… é‡æ–°å¤„ç†æ‰€æœ‰ `knowledge_base/` æ–‡ä»¶ï¼Œç”Ÿæˆ FAISS ç´¢å¼•"""
    print("ğŸš€ æ­£åœ¨åˆ›å»º FAISS ç´¢å¼•...")
    device = "cpu"  # âœ… å¼ºåˆ¶ä½¿ç”¨ CPUï¼Œé¿å… MPS é”™è¯¯
    embeddings = HuggingFaceEmbeddings(
        model_name="models/all-MiniLM-L6-v2",
        model_kwargs={"device": device}
    )

    all_docs = []
    for file in os.listdir(DATA_FOLDER):
        file_path = os.path.join(DATA_FOLDER, file)
        if file.endswith(".pdf"):
            all_docs.extend(process_pdf(file_path))
        elif file.endswith(".txt"):
            all_docs.extend(process_txt(file_path))
        elif file.endswith(".json"):
            all_docs.extend(process_json(file_path))

    if all_docs:
        print(f"âœ… å·²åŠ è½½ {len(all_docs)} æ¡æ–‡æ¡£æ•°æ®ï¼Œå‡†å¤‡åˆ›å»º FAISS ç´¢å¼•...")

        # âœ… æ”¹è¿›åˆ‡åˆ†ç­–ç•¥
        text_splitter = RecursiveCharacterTextSplitter(chunk_size=256, chunk_overlap=10)
        split_docs = text_splitter.split_documents(all_docs)

        # âœ… ç¡®ä¿ FAISS å­˜å‚¨çš„æ˜¯æ¸…æ™°çš„é—®ç­”æ•°æ®
        vectorstore = FAISS.from_documents(split_docs, embeddings)
        vectorstore.save_local(FAISS_INDEX_PATH)

        print(f"âœ… FAISS ç´¢å¼•åˆ›å»ºå®Œæˆï¼Œå­˜å…¥ {len(split_docs)} æ¡æ•°æ®ã€‚")
    else:
        print("âš ï¸ æ²¡æœ‰æœ‰æ•ˆçš„å†…å®¹å¯å­˜å…¥ FAISSã€‚")

def retrieve_faiss(query_text, top_k=1):
    """âœ… é€šè¿‡ FAISS å¬å›æœ€ç›¸ä¼¼çš„æ–‡æœ¬"""
    print(f"ğŸ” æ­£åœ¨æŸ¥è¯¢ FAISS: {query_text}")

    # âœ… ç¡®ä¿ç´¢å¼•å·²åŠ è½½
    print(f"ğŸ“‚ FAISS ç´¢å¼•è·¯å¾„: {FAISS_INDEX_PATH}")
    vectorstore = FAISS.load_local(
        FAISS_INDEX_PATH,
        HuggingFaceEmbeddings(model_name="models/all-MiniLM-L6-v2",
                              model_kwargs={"device": "cpu"}),  # âœ… å¼ºåˆ¶ä½¿ç”¨ CPU
        allow_dangerous_deserialization=True
    )

    # âœ… è®¡ç®—æŸ¥è¯¢å‘é‡
    docs = vectorstore.similarity_search(query_text, k=top_k)

    if docs:
        return docs[0].page_content  # è¿”å›æœ€åŒ¹é…çš„æ–‡æœ¬
    else:
        return "âš ï¸ æœªæ‰¾åˆ°ç›¸å…³æ–‡æœ¬ï¼"




if __name__ == "__main__":
    create_faiss_index()

    # âœ… æ£€æŸ¥ FAISS å¬å›ç»“æœ
    test_query = "How can we prevent foodborne illness?"
    retrieved_text = retrieve_faiss(test_query)
    print(f"âœ… æŸ¥è¯¢: {test_query}")
    print(f"ğŸ¯ FAISS å¬å›: {retrieved_text}")
